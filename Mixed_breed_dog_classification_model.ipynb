{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H_W73tcQmvu",
        "outputId": "d152250a-1fab-49b3-8cc1-18004696e0d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n",
            "Your runtime has 1081.4 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "  \n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abOccOwbd0Kg",
        "outputId": "d3dbb482-4b09-4721-f0c4-7ea625425170"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-01 11:44:30.665142: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "#Importing the Required Libraries\n",
        "from sklearn.datasets import load_files\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "\n",
        "def load_dataset(path):\n",
        "  data = load_files(path)\n",
        "  dog_files = np.array(data['filenames'])\n",
        "  dog_targets = np_utils.to_categorical(np.array(data['target']), 120)\n",
        "  return dog_files, dog_targets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWMq9cisGFj_"
      },
      "outputs": [],
      "source": [
        "#loading dataset\n",
        "X, Y = load_dataset(\"images/Images\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOkHdvqBdlGz"
      },
      "outputs": [],
      "source": [
        "dog_names = np.zeros(120, np.dtype('U200'))\n",
        "for i in range(len(X)):\n",
        "    s = X[i]\n",
        "    name = X[i].split(\"-\", 1)[1]\n",
        "    if \"/\" in name:\n",
        "      name = name.split(\"/\")[0]\n",
        "    #name = X[i].split('-')[1]\n",
        "    name_index = np.argmax(Y[i])\n",
        "    dog_names[name_index] = name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivW6CojPXXpG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_mixed_breed_dataset(image_path, percentages_path):\n",
        "    images = load_files(image_path)\n",
        "    percentages = pd.read_csv(percentages_path)\n",
        "    dog_files = np.array(images['filenames'])\n",
        "    image_cond = lambda x: np.all(x[-4:] == \".jpg\")\n",
        "    dog_files = dog_files[list(map(image_cond, dog_files))]\n",
        "    #percentages.set_index(percentages.loc[:,\"Image Name\"])\n",
        "    percentages = percentages.set_index(\"Image Name\")\n",
        "    get_name_f = lambda x: x.split(\"/\")[-1][:-4]\n",
        "    dog_image_names = np.array(list(map(get_name_f, dog_files)))\n",
        "    dog_targets = percentages.loc[dog_image_names]\n",
        "    dog_targets = dog_targets[dog_names]\n",
        "    return dog_files, dog_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lWg7ZMXvmYi"
      },
      "outputs": [],
      "source": [
        "dog_names = list(dog_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imsU0bTRXXpG"
      },
      "outputs": [],
      "source": [
        "# Training with mixedbreed dataset setting\n",
        "# To be segmented into training, validation, and test sets\n",
        "files, targets = load_mixed_breed_dataset(\"JP_Images_Single\", \"JP_Percentages_Normalized.csv\")\n",
        "\n",
        "# Kept as all files\n",
        "allfiles, alltargets = load_mixed_breed_dataset(\"JP_Images_Single\", \"JP_Percentages_Normalized.csv\")\n",
        "\n",
        "# Training with purebreed dataset setting\n",
        "#files, targets = X,Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUFatJ0UXXpG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "files_train, files_test, targets_train, targets_test = train_test_split(files, targets, test_size=0.25, random_state=87)\n",
        "\n",
        "files_train, files_val, targets_train, targets_val = train_test_split(files_train, targets_train, test_size=0.25, random_state=87) # 0.25 x 0.8 = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGUAxNzwXXpH",
        "outputId": "a0bf0830-5c85-4447-baf4-7731b091eabd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 60 total purebred dog images.\n",
            "\n",
            "There are 33 training purebred dog images.\n",
            "There are 12 validation purebred dog images.\n",
            "There are 15 test purebred dog images.\n",
            "There are total 120 dog breeds\n"
          ]
        }
      ],
      "source": [
        "# print statistics about the dataset\n",
        "print('There are %s total purebred dog images.\\n' % str(len(files)))\n",
        "print('There are %d training purebred dog images.' % len(files_train))\n",
        "print('There are %d validation purebred dog images.' % len(files_val))\n",
        "print('There are %d test purebred dog images.'% len(files_test))\n",
        "print('There are total {0} dog breeds'.format(len(dog_names)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcXqoBUKD1QH"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PI2zM1q6D7OX"
      },
      "outputs": [],
      "source": [
        "#Visualize some training examples\n",
        "\n",
        "def displayImage(img_path,ax):\n",
        "  image = cv2.imread(img_path)\n",
        "  ax.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))\n",
        "\n",
        "#sample = list(np.random.choice(x_train.shape[0],8))\n",
        "#fig = plt.figure(figsize=(20,10))\n",
        "#for index,im in enumerate(sample):\n",
        "#  ax = fig.add_subplot(3,4,index+1,xticks=[], yticks=[])\n",
        "#  displayImage(x_train[im],ax)\n",
        "#  ax.set_title(dog_names[int(np.argmax(y_train[im]))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUQIc_phFFeC"
      },
      "outputs": [],
      "source": [
        "def createdatasets(dataset):\n",
        "  data_set = np.zeros([dataset.shape[0],299,299,3])\n",
        "  for i,image_arr in enumerate(dataset):\n",
        "    img = cv2.imread(image_arr)\n",
        "    res = cv2.resize(img, dsize=(299, 299), interpolation=cv2.INTER_CUBIC)\n",
        "    data_set[i,:,:,:] = res\n",
        "  return data_set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-S5_tGNLdJI",
        "outputId": "a230e2bb-db08-4369-f4d9-204e8ff665ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-01 11:45:57.674548: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-01 11:45:57.684037: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"xception\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)          (None, 149, 149, 32  864         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1_conv1_bn (BatchNormaliz  (None, 149, 149, 32  128        ['block1_conv1[0][0]']           \n",
            " ation)                         )                                                                 \n",
            "                                                                                                  \n",
            " block1_conv1_act (Activation)  (None, 149, 149, 32  0           ['block1_conv1_bn[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)          (None, 147, 147, 64  18432       ['block1_conv1_act[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1_conv2_bn (BatchNormaliz  (None, 147, 147, 64  256        ['block1_conv2[0][0]']           \n",
            " ation)                         )                                                                 \n",
            "                                                                                                  \n",
            " block1_conv2_act (Activation)  (None, 147, 147, 64  0           ['block1_conv2_bn[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block2_sepconv1 (SeparableConv  (None, 147, 147, 12  8768       ['block1_conv2_act[0][0]']       \n",
            " 2D)                            8)                                                                \n",
            "                                                                                                  \n",
            " block2_sepconv1_bn (BatchNorma  (None, 147, 147, 12  512        ['block2_sepconv1[0][0]']        \n",
            " lization)                      8)                                                                \n",
            "                                                                                                  \n",
            " block2_sepconv2_act (Activatio  (None, 147, 147, 12  0          ['block2_sepconv1_bn[0][0]']     \n",
            " n)                             8)                                                                \n",
            "                                                                                                  \n",
            " block2_sepconv2 (SeparableConv  (None, 147, 147, 12  17536      ['block2_sepconv2_act[0][0]']    \n",
            " 2D)                            8)                                                                \n",
            "                                                                                                  \n",
            " block2_sepconv2_bn (BatchNorma  (None, 147, 147, 12  512        ['block2_sepconv2[0][0]']        \n",
            " lization)                      8)                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 74, 74, 128)  8192        ['block1_conv2_act[0][0]']       \n",
            "                                                                                                  \n",
            " block2_pool (MaxPooling2D)     (None, 74, 74, 128)  0           ['block2_sepconv2_bn[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 74, 74, 128)  512        ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 74, 74, 128)  0           ['block2_pool[0][0]',            \n",
            "                                                                  'batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " block3_sepconv1_act (Activatio  (None, 74, 74, 128)  0          ['add[0][0]']                    \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block3_sepconv1 (SeparableConv  (None, 74, 74, 256)  33920      ['block3_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3_sepconv1_bn (BatchNorma  (None, 74, 74, 256)  1024       ['block3_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3_sepconv2_act (Activatio  (None, 74, 74, 256)  0          ['block3_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block3_sepconv2 (SeparableConv  (None, 74, 74, 256)  67840      ['block3_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3_sepconv2_bn (BatchNorma  (None, 74, 74, 256)  1024       ['block3_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 37, 37, 256)  32768       ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " block3_pool (MaxPooling2D)     (None, 37, 37, 256)  0           ['block3_sepconv2_bn[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 37, 37, 256)  1024       ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 37, 37, 256)  0           ['block3_pool[0][0]',            \n",
            "                                                                  'batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " block4_sepconv1_act (Activatio  (None, 37, 37, 256)  0          ['add_1[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block4_sepconv1 (SeparableConv  (None, 37, 37, 728)  188672     ['block4_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4_sepconv1_bn (BatchNorma  (None, 37, 37, 728)  2912       ['block4_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4_sepconv2_act (Activatio  (None, 37, 37, 728)  0          ['block4_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block4_sepconv2 (SeparableConv  (None, 37, 37, 728)  536536     ['block4_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4_sepconv2_bn (BatchNorma  (None, 37, 37, 728)  2912       ['block4_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 19, 19, 728)  186368      ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " block4_pool (MaxPooling2D)     (None, 19, 19, 728)  0           ['block4_sepconv2_bn[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 19, 19, 728)  2912       ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 19, 19, 728)  0           ['block4_pool[0][0]',            \n",
            "                                                                  'batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " block5_sepconv1_act (Activatio  (None, 19, 19, 728)  0          ['add_2[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block5_sepconv1 (SeparableConv  (None, 19, 19, 728)  536536     ['block5_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5_sepconv1_bn (BatchNorma  (None, 19, 19, 728)  2912       ['block5_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5_sepconv2_act (Activatio  (None, 19, 19, 728)  0          ['block5_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block5_sepconv2 (SeparableConv  (None, 19, 19, 728)  536536     ['block5_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5_sepconv2_bn (BatchNorma  (None, 19, 19, 728)  2912       ['block5_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5_sepconv3_act (Activatio  (None, 19, 19, 728)  0          ['block5_sepconv2_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block5_sepconv3 (SeparableConv  (None, 19, 19, 728)  536536     ['block5_sepconv3_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5_sepconv3_bn (BatchNorma  (None, 19, 19, 728)  2912       ['block5_sepconv3[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 19, 19, 728)  0           ['block5_sepconv3_bn[0][0]',     \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " block6_sepconv1_act (Activatio  (None, 19, 19, 728)  0          ['add_3[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block6_sepconv1 (SeparableConv  (None, 19, 19, 728)  536536     ['block6_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6_sepconv1_bn (BatchNorma  (None, 19, 19, 728)  2912       ['block6_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6_sepconv2_act (Activatio  (None, 19, 19, 728)  0          ['block6_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block6_sepconv2 (SeparableConv  (None, 19, 19, 728)  536536     ['block6_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6_sepconv2_bn (BatchNorma  (None, 19, 19, 728)  2912       ['block6_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6_sepconv3_act (Activatio  (None, 19, 19, 728)  0          ['block6_sepconv2_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block6_sepconv3 (SeparableConv  (None, 19, 19, 728)  536536     ['block6_sepconv3_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6_sepconv3_bn (BatchNorma  (None, 19, 19, 728)  2912       ['block6_sepconv3[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 19, 19, 728)  0           ['block6_sepconv3_bn[0][0]',     \n",
            "                                                                  'add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " block7_sepconv1_act (Activatio  (None, 19, 19, 728)  0          ['add_4[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block7_sepconv1 (SeparableConv  (None, 19, 19, 728)  536536     ['block7_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block7_sepconv1_bn (BatchNorma  (None, 19, 19, 728)  2912       ['block7_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block7_sepconv2_act (Activatio  (None, 19, 19, 728)  0          ['block7_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block7_sepconv2 (SeparableConv  (None, 19, 19, 728)  536536     ['block7_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block7_sepconv2_bn (BatchNorma  (None, 19, 19, 728)  2912       ['block7_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block7_sepconv3_act (Activatio  (None, 19, 19, 728)  0          ['block7_sepconv2_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block7_sepconv3 (SeparableConv  (None, 19, 19, 728)  536536     ['block7_sepconv3_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block7_sepconv3_bn (BatchNorma  (None, 19, 19, 728)  2912       ['block7_sepconv3[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 19, 19, 728)  0           ['block7_sepconv3_bn[0][0]',     \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " block8_sepconv1_act (Activatio  (None, 19, 19, 728)  0          ['add_5[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block8_sepconv1 (SeparableConv  (None, 19, 19, 728)  536536     ['block8_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block8_sepconv1_bn (BatchNorma  (None, 19, 19, 728)  2912       ['block8_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block8_sepconv2_act (Activatio  (None, 19, 19, 728)  0          ['block8_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block8_sepconv2 (SeparableConv  (None, 19, 19, 728)  536536     ['block8_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block8_sepconv2_bn (BatchNorma  (None, 19, 19, 728)  2912       ['block8_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block8_sepconv3_act (Activatio  (None, 19, 19, 728)  0          ['block8_sepconv2_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block8_sepconv3 (SeparableConv  (None, 19, 19, 728)  536536     ['block8_sepconv3_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block8_sepconv3_bn (BatchNorma  (None, 19, 19, 728)  2912       ['block8_sepconv3[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 19, 19, 728)  0           ['block8_sepconv3_bn[0][0]',     \n",
            "                                                                  'add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " block9_sepconv1_act (Activatio  (None, 19, 19, 728)  0          ['add_6[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block9_sepconv1 (SeparableConv  (None, 19, 19, 728)  536536     ['block9_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block9_sepconv1_bn (BatchNorma  (None, 19, 19, 728)  2912       ['block9_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block9_sepconv2_act (Activatio  (None, 19, 19, 728)  0          ['block9_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block9_sepconv2 (SeparableConv  (None, 19, 19, 728)  536536     ['block9_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block9_sepconv2_bn (BatchNorma  (None, 19, 19, 728)  2912       ['block9_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block9_sepconv3_act (Activatio  (None, 19, 19, 728)  0          ['block9_sepconv2_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block9_sepconv3 (SeparableConv  (None, 19, 19, 728)  536536     ['block9_sepconv3_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block9_sepconv3_bn (BatchNorma  (None, 19, 19, 728)  2912       ['block9_sepconv3[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 19, 19, 728)  0           ['block9_sepconv3_bn[0][0]',     \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " block10_sepconv1_act (Activati  (None, 19, 19, 728)  0          ['add_7[0][0]']                  \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block10_sepconv1 (SeparableCon  (None, 19, 19, 728)  536536     ['block10_sepconv1_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block10_sepconv1_bn (BatchNorm  (None, 19, 19, 728)  2912       ['block10_sepconv1[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block10_sepconv2_act (Activati  (None, 19, 19, 728)  0          ['block10_sepconv1_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block10_sepconv2 (SeparableCon  (None, 19, 19, 728)  536536     ['block10_sepconv2_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block10_sepconv2_bn (BatchNorm  (None, 19, 19, 728)  2912       ['block10_sepconv2[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block10_sepconv3_act (Activati  (None, 19, 19, 728)  0          ['block10_sepconv2_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block10_sepconv3 (SeparableCon  (None, 19, 19, 728)  536536     ['block10_sepconv3_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block10_sepconv3_bn (BatchNorm  (None, 19, 19, 728)  2912       ['block10_sepconv3[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 19, 19, 728)  0           ['block10_sepconv3_bn[0][0]',    \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " block11_sepconv1_act (Activati  (None, 19, 19, 728)  0          ['add_8[0][0]']                  \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block11_sepconv1 (SeparableCon  (None, 19, 19, 728)  536536     ['block11_sepconv1_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block11_sepconv1_bn (BatchNorm  (None, 19, 19, 728)  2912       ['block11_sepconv1[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block11_sepconv2_act (Activati  (None, 19, 19, 728)  0          ['block11_sepconv1_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block11_sepconv2 (SeparableCon  (None, 19, 19, 728)  536536     ['block11_sepconv2_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block11_sepconv2_bn (BatchNorm  (None, 19, 19, 728)  2912       ['block11_sepconv2[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block11_sepconv3_act (Activati  (None, 19, 19, 728)  0          ['block11_sepconv2_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block11_sepconv3 (SeparableCon  (None, 19, 19, 728)  536536     ['block11_sepconv3_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block11_sepconv3_bn (BatchNorm  (None, 19, 19, 728)  2912       ['block11_sepconv3[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 19, 19, 728)  0           ['block11_sepconv3_bn[0][0]',    \n",
            "                                                                  'add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " block12_sepconv1_act (Activati  (None, 19, 19, 728)  0          ['add_9[0][0]']                  \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block12_sepconv1 (SeparableCon  (None, 19, 19, 728)  536536     ['block12_sepconv1_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block12_sepconv1_bn (BatchNorm  (None, 19, 19, 728)  2912       ['block12_sepconv1[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block12_sepconv2_act (Activati  (None, 19, 19, 728)  0          ['block12_sepconv1_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block12_sepconv2 (SeparableCon  (None, 19, 19, 728)  536536     ['block12_sepconv2_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block12_sepconv2_bn (BatchNorm  (None, 19, 19, 728)  2912       ['block12_sepconv2[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block12_sepconv3_act (Activati  (None, 19, 19, 728)  0          ['block12_sepconv2_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block12_sepconv3 (SeparableCon  (None, 19, 19, 728)  536536     ['block12_sepconv3_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block12_sepconv3_bn (BatchNorm  (None, 19, 19, 728)  2912       ['block12_sepconv3[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 19, 19, 728)  0           ['block12_sepconv3_bn[0][0]',    \n",
            "                                                                  'add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " block13_sepconv1_act (Activati  (None, 19, 19, 728)  0          ['add_10[0][0]']                 \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block13_sepconv1 (SeparableCon  (None, 19, 19, 728)  536536     ['block13_sepconv1_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block13_sepconv1_bn (BatchNorm  (None, 19, 19, 728)  2912       ['block13_sepconv1[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block13_sepconv2_act (Activati  (None, 19, 19, 728)  0          ['block13_sepconv1_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block13_sepconv2 (SeparableCon  (None, 19, 19, 1024  752024     ['block13_sepconv2_act[0][0]']   \n",
            " v2D)                           )                                                                 \n",
            "                                                                                                  \n",
            " block13_sepconv2_bn (BatchNorm  (None, 19, 19, 1024  4096       ['block13_sepconv2[0][0]']       \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 10, 10, 1024  745472      ['add_10[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block13_pool (MaxPooling2D)    (None, 10, 10, 1024  0           ['block13_sepconv2_bn[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 10, 10, 1024  4096       ['conv2d_3[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 10, 10, 1024  0           ['block13_pool[0][0]',           \n",
            "                                )                                 'batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " block14_sepconv1 (SeparableCon  (None, 10, 10, 1536  1582080    ['add_11[0][0]']                 \n",
            " v2D)                           )                                                                 \n",
            "                                                                                                  \n",
            " block14_sepconv1_bn (BatchNorm  (None, 10, 10, 1536  6144       ['block14_sepconv1[0][0]']       \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " block14_sepconv1_act (Activati  (None, 10, 10, 1536  0          ['block14_sepconv1_bn[0][0]']    \n",
            " on)                            )                                                                 \n",
            "                                                                                                  \n",
            " block14_sepconv2 (SeparableCon  (None, 10, 10, 2048  3159552    ['block14_sepconv1_act[0][0]']   \n",
            " v2D)                           )                                                                 \n",
            "                                                                                                  \n",
            " block14_sepconv2_bn (BatchNorm  (None, 10, 10, 2048  8192       ['block14_sepconv2[0][0]']       \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " block14_sepconv2_act (Activati  (None, 10, 10, 2048  0          ['block14_sepconv2_bn[0][0]']    \n",
            " on)                            )                                                                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 20,861,480\n",
            "Trainable params: 20,806,952\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# importing Xception model using Keras. We have to remove the last layer and as we are removing the last layer\n",
        "# we have to provide the Input tensor\n",
        "from keras.applications.xception import Xception\n",
        "from keras.layers import Input\n",
        "newinput = Input(shape=(299,299,3))\n",
        "model = Xception(include_top=False,input_tensor=newinput)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g14IJa18esqv"
      },
      "outputs": [],
      "source": [
        "#Setting all the layers to non-trainable\n",
        "for layer in model.layers:\n",
        "  layer.trainable = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl5EX-oOYsMz"
      },
      "outputs": [],
      "source": [
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l87mK5_id6Vj"
      },
      "outputs": [],
      "source": [
        "from keras.applications.xception import preprocess_input\n",
        "from keras.backend import expand_dims\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vn5fEp0bYZfS"
      },
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vjwx83kmI7zD"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input,Conv2D,MaxPooling2D,Dense,Dropout,BatchNormalization\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmKSO9TJWvCK"
      },
      "outputs": [],
      "source": [
        "#defining the new last layer of the model \n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "model1=Sequential()\n",
        "\n",
        "\n",
        "model1.add(GlobalAveragePooling2D(input_shape=(10,10,2048)))\n",
        "\n",
        "\n",
        "model1.add(Dense(120,activation='softmax'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cddzFhFvZbme",
        "outputId": "fe84e3d2-29ba-4e98-c457-a2c5f94ddff9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 120)               245880    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 245,880\n",
            "Trainable params: 245,880\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ge8ldN_0XXpJ",
        "outputId": "f6487dc9-f4bc-4507-c41b-6524fec956f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 3s 705ms/step\n",
            "2/2 [==============================] - 2s 795ms/step\n"
          ]
        }
      ],
      "source": [
        "# bottleneck to reduce excess computation - pass all the images once and use that during training.\n",
        "\n",
        "#bottleneck for segmented mixed breed dataset\n",
        "bottle_neck_set_segmented = model.predict(preprocess_input(createdatasets(files)),verbose=1)\n",
        "\n",
        "#bottleneck for complete mixed breed dataset\n",
        "bottle_neck_set_complete = model.predict(preprocess_input(createdatasets(allfiles)),verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5A0l8-uwaxV",
        "outputId": "a52c2614-3fc1-4e1b-ce73-3edea91dd324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60, 10, 10, 2048)\n",
            "(60, 120)\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 460ms/step - loss: 7.8254 - accuracy: 0.0000e+00 - val_loss: 9.6796 - val_accuracy: 0.1667\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 7.4618 - accuracy: 0.0000e+00 - val_loss: 9.4310 - val_accuracy: 0.1667\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 7.1125 - accuracy: 0.0303 - val_loss: 9.1992 - val_accuracy: 0.0833\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 6.7799 - accuracy: 0.1515 - val_loss: 8.9871 - val_accuracy: 0.0833\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 6.4662 - accuracy: 0.1515 - val_loss: 8.7977 - val_accuracy: 0.0833\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 6.1726 - accuracy: 0.1515 - val_loss: 8.6323 - val_accuracy: 0.0833\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 5.8993 - accuracy: 0.1515 - val_loss: 8.4909 - val_accuracy: 0.0833\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 5.6453 - accuracy: 0.1515 - val_loss: 8.3723 - val_accuracy: 0.0833\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 5.4092 - accuracy: 0.1818 - val_loss: 8.2746 - val_accuracy: 0.0833\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 5.1891 - accuracy: 0.1818 - val_loss: 8.1956 - val_accuracy: 0.0833\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 256ms/step - loss: 4.9834 - accuracy: 0.2121 - val_loss: 8.1333 - val_accuracy: 0.0833\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 4.7907 - accuracy: 0.2121 - val_loss: 8.0860 - val_accuracy: 0.0833\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 4.6094 - accuracy: 0.2121 - val_loss: 8.0521 - val_accuracy: 0.0833\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 4.4384 - accuracy: 0.2121 - val_loss: 8.0299 - val_accuracy: 0.0833\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 4.2766 - accuracy: 0.2121 - val_loss: 8.0176 - val_accuracy: 0.0833\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.1234 - accuracy: 0.2727 - val_loss: 8.0136 - val_accuracy: 0.0833\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 3.9783 - accuracy: 0.2727 - val_loss: 8.0157 - val_accuracy: 0.0833\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 3.8410 - accuracy: 0.2727 - val_loss: 8.0220 - val_accuracy: 0.0833\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 3.7115 - accuracy: 0.3030 - val_loss: 8.0305 - val_accuracy: 0.0833\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 3.5898 - accuracy: 0.2727 - val_loss: 8.0395 - val_accuracy: 0.0833\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 3.4757 - accuracy: 0.2727 - val_loss: 8.0471 - val_accuracy: 0.0833\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 3.3692 - accuracy: 0.3030 - val_loss: 8.0519 - val_accuracy: 0.1667\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 3.2699 - accuracy: 0.3030 - val_loss: 8.0527 - val_accuracy: 0.1667\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 3.1771 - accuracy: 0.3030 - val_loss: 8.0489 - val_accuracy: 0.1667\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 3.0901 - accuracy: 0.2727 - val_loss: 8.0398 - val_accuracy: 0.1667\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 3.0079 - accuracy: 0.3030 - val_loss: 8.0256 - val_accuracy: 0.1667\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 2.9297 - accuracy: 0.3636 - val_loss: 8.0063 - val_accuracy: 0.1667\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 2.8550 - accuracy: 0.3636 - val_loss: 7.9826 - val_accuracy: 0.1667\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 2.7832 - accuracy: 0.4242 - val_loss: 7.9549 - val_accuracy: 0.1667\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 2.7141 - accuracy: 0.4242 - val_loss: 7.9241 - val_accuracy: 0.1667\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 2.6476 - accuracy: 0.4242 - val_loss: 7.8909 - val_accuracy: 0.1667\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 2.5837 - accuracy: 0.4545 - val_loss: 7.8561 - val_accuracy: 0.1667\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.5226 - accuracy: 0.4545 - val_loss: 7.8206 - val_accuracy: 0.1667\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 2.4642 - accuracy: 0.4848 - val_loss: 7.7852 - val_accuracy: 0.1667\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.4088 - accuracy: 0.5455 - val_loss: 7.7505 - val_accuracy: 0.1667\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 2.3563 - accuracy: 0.5455 - val_loss: 7.7172 - val_accuracy: 0.1667\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 2.3068 - accuracy: 0.5455 - val_loss: 7.6859 - val_accuracy: 0.1667\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 2.2602 - accuracy: 0.5758 - val_loss: 7.6570 - val_accuracy: 0.1667\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 2.2164 - accuracy: 0.6364 - val_loss: 7.6307 - val_accuracy: 0.1667\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 2.1751 - accuracy: 0.6364 - val_loss: 7.6072 - val_accuracy: 0.1667\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 2.1362 - accuracy: 0.6667 - val_loss: 7.5864 - val_accuracy: 0.1667\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 2.0994 - accuracy: 0.6667 - val_loss: 7.5682 - val_accuracy: 0.1667\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 2.0647 - accuracy: 0.6667 - val_loss: 7.5523 - val_accuracy: 0.1667\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 2.0319 - accuracy: 0.6970 - val_loss: 7.5386 - val_accuracy: 0.1667\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 2.0011 - accuracy: 0.6970 - val_loss: 7.5267 - val_accuracy: 0.1667\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 1.9721 - accuracy: 0.7273 - val_loss: 7.5164 - val_accuracy: 0.1667\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.9451 - accuracy: 0.7273 - val_loss: 7.5074 - val_accuracy: 0.1667\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 1.9200 - accuracy: 0.6970 - val_loss: 7.4995 - val_accuracy: 0.1667\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 1.8966 - accuracy: 0.7576 - val_loss: 7.4927 - val_accuracy: 0.1667\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 1.8750 - accuracy: 0.7576 - val_loss: 7.4866 - val_accuracy: 0.1667\n",
            "Test Set Accuracy 33.33333333333333%\n",
            "Mixed Breed Test Set Accuracy 51.66666666666667%\n",
            "Mixed Breed Test Set Top-5 Set Average 2.566666666666667\n",
            "Mixed Breed Test Set Average Distance 0.9414169474208764\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 7.7502 - accuracy: 0.0909 - val_loss: 6.7085 - val_accuracy: 0.1667\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 7.4035 - accuracy: 0.0909 - val_loss: 6.5453 - val_accuracy: 0.1667\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 7.0707 - accuracy: 0.0909 - val_loss: 6.3961 - val_accuracy: 0.2500\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 6.7543 - accuracy: 0.1515 - val_loss: 6.2585 - val_accuracy: 0.2500\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 6.4568 - accuracy: 0.1515 - val_loss: 6.1306 - val_accuracy: 0.2500\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 6.1794 - accuracy: 0.1818 - val_loss: 6.0111 - val_accuracy: 0.2500\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 5.9216 - accuracy: 0.1515 - val_loss: 5.8990 - val_accuracy: 0.2500\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 5.6818 - accuracy: 0.1515 - val_loss: 5.7938 - val_accuracy: 0.2500\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 5.4582 - accuracy: 0.1818 - val_loss: 5.6948 - val_accuracy: 0.2500\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 5.2493 - accuracy: 0.2121 - val_loss: 5.6016 - val_accuracy: 0.2500\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 5.0541 - accuracy: 0.2424 - val_loss: 5.5136 - val_accuracy: 0.2500\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 4.8719 - accuracy: 0.2424 - val_loss: 5.4306 - val_accuracy: 0.2500\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 4.7017 - accuracy: 0.2424 - val_loss: 5.3526 - val_accuracy: 0.2500\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 4.5428 - accuracy: 0.2727 - val_loss: 5.2798 - val_accuracy: 0.2500\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 4.3940 - accuracy: 0.2727 - val_loss: 5.2126 - val_accuracy: 0.2500\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 4.2546 - accuracy: 0.2727 - val_loss: 5.1514 - val_accuracy: 0.2500\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 4.1237 - accuracy: 0.2727 - val_loss: 5.0961 - val_accuracy: 0.2500\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 4.0004 - accuracy: 0.2727 - val_loss: 5.0466 - val_accuracy: 0.2500\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 3.8842 - accuracy: 0.3030 - val_loss: 5.0026 - val_accuracy: 0.2500\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 3.7744 - accuracy: 0.2727 - val_loss: 4.9632 - val_accuracy: 0.2500\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 3.6705 - accuracy: 0.2727 - val_loss: 4.9280 - val_accuracy: 0.2500\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 3.5716 - accuracy: 0.3636 - val_loss: 4.8962 - val_accuracy: 0.2500\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 3.4771 - accuracy: 0.3939 - val_loss: 4.8672 - val_accuracy: 0.2500\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 3.3863 - accuracy: 0.4242 - val_loss: 4.8405 - val_accuracy: 0.2500\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.2984 - accuracy: 0.4242 - val_loss: 4.8157 - val_accuracy: 0.2500\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 3.2129 - accuracy: 0.4242 - val_loss: 4.7925 - val_accuracy: 0.2500\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 3.1297 - accuracy: 0.4242 - val_loss: 4.7708 - val_accuracy: 0.2500\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 3.0484 - accuracy: 0.4242 - val_loss: 4.7505 - val_accuracy: 0.2500\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 2.9692 - accuracy: 0.4242 - val_loss: 4.7315 - val_accuracy: 0.2500\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.8921 - accuracy: 0.4242 - val_loss: 4.7141 - val_accuracy: 0.2500\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 2.8175 - accuracy: 0.4242 - val_loss: 4.6983 - val_accuracy: 0.2500\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 2.7455 - accuracy: 0.4242 - val_loss: 4.6840 - val_accuracy: 0.2500\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 2.6764 - accuracy: 0.4545 - val_loss: 4.6715 - val_accuracy: 0.2500\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 2.6104 - accuracy: 0.5455 - val_loss: 4.6606 - val_accuracy: 0.2500\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 2.5474 - accuracy: 0.5455 - val_loss: 4.6513 - val_accuracy: 0.2500\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 2.4875 - accuracy: 0.5152 - val_loss: 4.6435 - val_accuracy: 0.2500\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 2.4305 - accuracy: 0.5152 - val_loss: 4.6370 - val_accuracy: 0.2500\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 2.3762 - accuracy: 0.5152 - val_loss: 4.6315 - val_accuracy: 0.1667\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 2.3243 - accuracy: 0.4848 - val_loss: 4.6268 - val_accuracy: 0.1667\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.2748 - accuracy: 0.5152 - val_loss: 4.6227 - val_accuracy: 0.1667\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 2.2273 - accuracy: 0.5455 - val_loss: 4.6188 - val_accuracy: 0.1667\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 2.1819 - accuracy: 0.5758 - val_loss: 4.6149 - val_accuracy: 0.1667\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 2.1384 - accuracy: 0.5758 - val_loss: 4.6109 - val_accuracy: 0.1667\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 2.0970 - accuracy: 0.6364 - val_loss: 4.6066 - val_accuracy: 0.1667\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 2.0576 - accuracy: 0.6667 - val_loss: 4.6018 - val_accuracy: 0.1667\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 2.0202 - accuracy: 0.6970 - val_loss: 4.5966 - val_accuracy: 0.1667\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 1.9848 - accuracy: 0.7273 - val_loss: 4.5909 - val_accuracy: 0.1667\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 1.9513 - accuracy: 0.7273 - val_loss: 4.5846 - val_accuracy: 0.1667\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 1.9196 - accuracy: 0.6970 - val_loss: 4.5778 - val_accuracy: 0.1667\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 1.8897 - accuracy: 0.6970 - val_loss: 4.5706 - val_accuracy: 0.1667\n",
            "Test Set Accuracy 20.0%\n",
            "Mixed Breed Test Set Accuracy 46.666666666666664%\n",
            "Mixed Breed Test Set Top-5 Set Average 2.5166666666666666\n",
            "Mixed Breed Test Set Average Distance 0.9692658312365021\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 8.3001 - accuracy: 0.0909 - val_loss: 7.2749 - val_accuracy: 0.1667\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 7.9291 - accuracy: 0.0909 - val_loss: 7.1814 - val_accuracy: 0.1667\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 7.5695 - accuracy: 0.0909 - val_loss: 7.1013 - val_accuracy: 0.1667\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 7.2240 - accuracy: 0.0909 - val_loss: 7.0292 - val_accuracy: 0.1667\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 6.8954 - accuracy: 0.1212 - val_loss: 6.9620 - val_accuracy: 0.1667\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 6.5863 - accuracy: 0.1212 - val_loss: 6.8979 - val_accuracy: 0.0833\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 6.2994 - accuracy: 0.1212 - val_loss: 6.8359 - val_accuracy: 0.0833\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 6.0361 - accuracy: 0.0909 - val_loss: 6.7750 - val_accuracy: 0.0833\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 5.7967 - accuracy: 0.1212 - val_loss: 6.7141 - val_accuracy: 0.0833\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 5.5792 - accuracy: 0.1212 - val_loss: 6.6526 - val_accuracy: 0.0833\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 5.3806 - accuracy: 0.1515 - val_loss: 6.5901 - val_accuracy: 0.0833\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 5.1971 - accuracy: 0.1515 - val_loss: 6.5268 - val_accuracy: 0.0833\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 5.0257 - accuracy: 0.1515 - val_loss: 6.4634 - val_accuracy: 0.0833\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 4.8643 - accuracy: 0.1818 - val_loss: 6.4007 - val_accuracy: 0.0833\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 4.7114 - accuracy: 0.1818 - val_loss: 6.3398 - val_accuracy: 0.0833\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 4.5661 - accuracy: 0.1818 - val_loss: 6.2813 - val_accuracy: 0.0833\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 4.4277 - accuracy: 0.1818 - val_loss: 6.2258 - val_accuracy: 0.0833\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 4.2958 - accuracy: 0.2121 - val_loss: 6.1735 - val_accuracy: 0.0833\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 4.1700 - accuracy: 0.2121 - val_loss: 6.1245 - val_accuracy: 0.0833\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 4.0496 - accuracy: 0.2424 - val_loss: 6.0785 - val_accuracy: 0.1667\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 3.9342 - accuracy: 0.2727 - val_loss: 6.0352 - val_accuracy: 0.1667\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.8235 - accuracy: 0.2727 - val_loss: 5.9940 - val_accuracy: 0.1667\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 3.7170 - accuracy: 0.2727 - val_loss: 5.9546 - val_accuracy: 0.1667\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 3.6146 - accuracy: 0.2727 - val_loss: 5.9164 - val_accuracy: 0.1667\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 3.5160 - accuracy: 0.3030 - val_loss: 5.8794 - val_accuracy: 0.1667\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.4211 - accuracy: 0.3030 - val_loss: 5.8431 - val_accuracy: 0.1667\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 3.3297 - accuracy: 0.3030 - val_loss: 5.8078 - val_accuracy: 0.1667\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 3.2418 - accuracy: 0.3636 - val_loss: 5.7734 - val_accuracy: 0.1667\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 3.1574 - accuracy: 0.3636 - val_loss: 5.7402 - val_accuracy: 0.1667\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 3.0766 - accuracy: 0.4242 - val_loss: 5.7086 - val_accuracy: 0.1667\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 2.9994 - accuracy: 0.4545 - val_loss: 5.6787 - val_accuracy: 0.1667\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 2.9259 - accuracy: 0.5152 - val_loss: 5.6508 - val_accuracy: 0.1667\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 2.8561 - accuracy: 0.5152 - val_loss: 5.6253 - val_accuracy: 0.1667\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 2.7899 - accuracy: 0.5152 - val_loss: 5.6023 - val_accuracy: 0.1667\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.7273 - accuracy: 0.5152 - val_loss: 5.5818 - val_accuracy: 0.1667\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 2.6678 - accuracy: 0.5152 - val_loss: 5.5637 - val_accuracy: 0.1667\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.6114 - accuracy: 0.5152 - val_loss: 5.5480 - val_accuracy: 0.1667\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 2.5577 - accuracy: 0.5152 - val_loss: 5.5343 - val_accuracy: 0.1667\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 2.5065 - accuracy: 0.5758 - val_loss: 5.5224 - val_accuracy: 0.1667\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 2.4575 - accuracy: 0.5758 - val_loss: 5.5119 - val_accuracy: 0.1667\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 2.4106 - accuracy: 0.6061 - val_loss: 5.5025 - val_accuracy: 0.1667\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 2.3657 - accuracy: 0.6061 - val_loss: 5.4938 - val_accuracy: 0.1667\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.3228 - accuracy: 0.6061 - val_loss: 5.4857 - val_accuracy: 0.1667\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.2817 - accuracy: 0.6061 - val_loss: 5.4778 - val_accuracy: 0.1667\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 2.2425 - accuracy: 0.6364 - val_loss: 5.4701 - val_accuracy: 0.1667\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 2.2049 - accuracy: 0.6061 - val_loss: 5.4624 - val_accuracy: 0.1667\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 2.1691 - accuracy: 0.6061 - val_loss: 5.4547 - val_accuracy: 0.1667\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 2.1349 - accuracy: 0.6364 - val_loss: 5.4470 - val_accuracy: 0.1667\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 2.1024 - accuracy: 0.6364 - val_loss: 5.4394 - val_accuracy: 0.2500\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 2.0714 - accuracy: 0.6970 - val_loss: 5.4319 - val_accuracy: 0.2500\n",
            "Test Set Accuracy 26.666666666666668%\n",
            "Mixed Breed Test Set Accuracy 50.0%\n",
            "Mixed Breed Test Set Top-5 Set Average 2.55\n",
            "Mixed Breed Test Set Average Distance 0.9758761624660294\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 417ms/step - loss: 8.3056 - accuracy: 0.1212 - val_loss: 6.0311 - val_accuracy: 0.1667\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 7.9575 - accuracy: 0.1212 - val_loss: 5.9062 - val_accuracy: 0.1667\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 7.6219 - accuracy: 0.1212 - val_loss: 5.8009 - val_accuracy: 0.3333\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 7.3004 - accuracy: 0.1212 - val_loss: 5.7166 - val_accuracy: 0.3333\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 6.9940 - accuracy: 0.1515 - val_loss: 5.6535 - val_accuracy: 0.3333\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 6.7036 - accuracy: 0.1818 - val_loss: 5.6108 - val_accuracy: 0.3333\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 6.4296 - accuracy: 0.1818 - val_loss: 5.5863 - val_accuracy: 0.3333\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 6.1724 - accuracy: 0.1515 - val_loss: 5.5772 - val_accuracy: 0.3333\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 5.9315 - accuracy: 0.1515 - val_loss: 5.5804 - val_accuracy: 0.3333\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 5.7062 - accuracy: 0.1515 - val_loss: 5.5932 - val_accuracy: 0.3333\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 5.4952 - accuracy: 0.1515 - val_loss: 5.6135 - val_accuracy: 0.3333\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 5.2970 - accuracy: 0.1515 - val_loss: 5.6397 - val_accuracy: 0.3333\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 5.1101 - accuracy: 0.1515 - val_loss: 5.6705 - val_accuracy: 0.3333\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 4.9332 - accuracy: 0.1515 - val_loss: 5.7049 - val_accuracy: 0.3333\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 4.7653 - accuracy: 0.1515 - val_loss: 5.7421 - val_accuracy: 0.3333\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 4.6056 - accuracy: 0.1515 - val_loss: 5.7812 - val_accuracy: 0.3333\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 4.4538 - accuracy: 0.1515 - val_loss: 5.8214 - val_accuracy: 0.3333\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 382ms/step - loss: 4.3097 - accuracy: 0.1515 - val_loss: 5.8619 - val_accuracy: 0.3333\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 4.1731 - accuracy: 0.1515 - val_loss: 5.9022 - val_accuracy: 0.3333\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 4.0438 - accuracy: 0.1515 - val_loss: 5.9415 - val_accuracy: 0.3333\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 386ms/step - loss: 3.9217 - accuracy: 0.1818 - val_loss: 5.9791 - val_accuracy: 0.3333\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 3.8064 - accuracy: 0.1818 - val_loss: 6.0145 - val_accuracy: 0.3333\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 3.6975 - accuracy: 0.1818 - val_loss: 6.0471 - val_accuracy: 0.3333\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 3.5946 - accuracy: 0.2121 - val_loss: 6.0766 - val_accuracy: 0.3333\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 3.4969 - accuracy: 0.2424 - val_loss: 6.1025 - val_accuracy: 0.3333\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 3.4037 - accuracy: 0.2727 - val_loss: 6.1246 - val_accuracy: 0.3333\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 267ms/step - loss: 3.3145 - accuracy: 0.3030 - val_loss: 6.1430 - val_accuracy: 0.3333\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 3.2285 - accuracy: 0.3333 - val_loss: 6.1576 - val_accuracy: 0.3333\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 3.1453 - accuracy: 0.3636 - val_loss: 6.1687 - val_accuracy: 0.3333\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 3.0646 - accuracy: 0.3939 - val_loss: 6.1765 - val_accuracy: 0.3333\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 2.9864 - accuracy: 0.3939 - val_loss: 6.1814 - val_accuracy: 0.3333\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 2.9107 - accuracy: 0.3939 - val_loss: 6.1836 - val_accuracy: 0.3333\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 356ms/step - loss: 2.8377 - accuracy: 0.3939 - val_loss: 6.1837 - val_accuracy: 0.3333\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.7675 - accuracy: 0.4242 - val_loss: 6.1820 - val_accuracy: 0.3333\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 2.7003 - accuracy: 0.4242 - val_loss: 6.1791 - val_accuracy: 0.3333\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.6362 - accuracy: 0.4242 - val_loss: 6.1753 - val_accuracy: 0.3333\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.5754 - accuracy: 0.4242 - val_loss: 6.1712 - val_accuracy: 0.3333\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 2.5177 - accuracy: 0.4242 - val_loss: 6.1673 - val_accuracy: 0.3333\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 2.4631 - accuracy: 0.4848 - val_loss: 6.1640 - val_accuracy: 0.3333\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.4114 - accuracy: 0.5455 - val_loss: 6.1616 - val_accuracy: 0.3333\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 2.3625 - accuracy: 0.5758 - val_loss: 6.1602 - val_accuracy: 0.3333\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 2.3160 - accuracy: 0.5758 - val_loss: 6.1602 - val_accuracy: 0.3333\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 2.2721 - accuracy: 0.6061 - val_loss: 6.1613 - val_accuracy: 0.3333\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 2.2305 - accuracy: 0.6061 - val_loss: 6.1635 - val_accuracy: 0.3333\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 2.1912 - accuracy: 0.6364 - val_loss: 6.1666 - val_accuracy: 0.3333\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 330ms/step - loss: 2.1542 - accuracy: 0.6061 - val_loss: 6.1704 - val_accuracy: 0.3333\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 2.1193 - accuracy: 0.6061 - val_loss: 6.1746 - val_accuracy: 0.3333\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.0866 - accuracy: 0.6061 - val_loss: 6.1789 - val_accuracy: 0.3333\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 2.0558 - accuracy: 0.6061 - val_loss: 6.1830 - val_accuracy: 0.3333\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.0269 - accuracy: 0.6061 - val_loss: 6.1868 - val_accuracy: 0.3333\n",
            "Test Set Accuracy 26.666666666666668%\n",
            "Mixed Breed Test Set Accuracy 46.666666666666664%\n",
            "Mixed Breed Test Set Top-5 Set Average 2.5\n",
            "Mixed Breed Test Set Average Distance 0.962806519326852\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 8.6208 - accuracy: 0.0303 - val_loss: 7.2212 - val_accuracy: 0.2500\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 8.2535 - accuracy: 0.0303 - val_loss: 7.0608 - val_accuracy: 0.2500\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 7.9024 - accuracy: 0.0303 - val_loss: 6.9055 - val_accuracy: 0.2500\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.5699 - accuracy: 0.1515 - val_loss: 6.7561 - val_accuracy: 0.2500\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 7.2582 - accuracy: 0.1515 - val_loss: 6.6142 - val_accuracy: 0.2500\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.9678 - accuracy: 0.1515 - val_loss: 6.4814 - val_accuracy: 0.2500\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 6.6974 - accuracy: 0.1515 - val_loss: 6.3593 - val_accuracy: 0.2500\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.4447 - accuracy: 0.1515 - val_loss: 6.2491 - val_accuracy: 0.2500\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 6.2077 - accuracy: 0.1818 - val_loss: 6.1517 - val_accuracy: 0.2500\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 5.9847 - accuracy: 0.1818 - val_loss: 6.0675 - val_accuracy: 0.2500\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 5.7744 - accuracy: 0.2121 - val_loss: 5.9965 - val_accuracy: 0.2500\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.5757 - accuracy: 0.2121 - val_loss: 5.9378 - val_accuracy: 0.2500\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 5.3878 - accuracy: 0.2424 - val_loss: 5.8907 - val_accuracy: 0.2500\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 5.2101 - accuracy: 0.2424 - val_loss: 5.8539 - val_accuracy: 0.2500\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 5.0419 - accuracy: 0.2121 - val_loss: 5.8261 - val_accuracy: 0.2500\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 4.8827 - accuracy: 0.2121 - val_loss: 5.8060 - val_accuracy: 0.2500\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 4.7319 - accuracy: 0.2121 - val_loss: 5.7923 - val_accuracy: 0.2500\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 4.5888 - accuracy: 0.2121 - val_loss: 5.7840 - val_accuracy: 0.2500\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.4530 - accuracy: 0.2121 - val_loss: 5.7800 - val_accuracy: 0.2500\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 4.3238 - accuracy: 0.2121 - val_loss: 5.7795 - val_accuracy: 0.2500\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.2006 - accuracy: 0.1818 - val_loss: 5.7816 - val_accuracy: 0.2500\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 4.0830 - accuracy: 0.1818 - val_loss: 5.7858 - val_accuracy: 0.2500\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 3.9704 - accuracy: 0.1818 - val_loss: 5.7913 - val_accuracy: 0.2500\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 3.8624 - accuracy: 0.1818 - val_loss: 5.7978 - val_accuracy: 0.2500\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 3.7584 - accuracy: 0.2424 - val_loss: 5.8046 - val_accuracy: 0.2500\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 3.6583 - accuracy: 0.2424 - val_loss: 5.8113 - val_accuracy: 0.2500\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 3.5616 - accuracy: 0.2424 - val_loss: 5.8174 - val_accuracy: 0.2500\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 3.4681 - accuracy: 0.2727 - val_loss: 5.8224 - val_accuracy: 0.2500\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 3.3778 - accuracy: 0.3030 - val_loss: 5.8260 - val_accuracy: 0.2500\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 3.2906 - accuracy: 0.3030 - val_loss: 5.8279 - val_accuracy: 0.2500\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 3.2064 - accuracy: 0.3333 - val_loss: 5.8278 - val_accuracy: 0.2500\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 3.1252 - accuracy: 0.3939 - val_loss: 5.8256 - val_accuracy: 0.2500\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 3.0471 - accuracy: 0.4545 - val_loss: 5.8213 - val_accuracy: 0.2500\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 2.9721 - accuracy: 0.4545 - val_loss: 5.8152 - val_accuracy: 0.2500\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.9002 - accuracy: 0.4848 - val_loss: 5.8073 - val_accuracy: 0.2500\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 2.8314 - accuracy: 0.4848 - val_loss: 5.7980 - val_accuracy: 0.2500\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 2.7655 - accuracy: 0.4848 - val_loss: 5.7876 - val_accuracy: 0.2500\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.7025 - accuracy: 0.4848 - val_loss: 5.7765 - val_accuracy: 0.2500\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 2.6423 - accuracy: 0.4848 - val_loss: 5.7649 - val_accuracy: 0.2500\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 2.5846 - accuracy: 0.4848 - val_loss: 5.7533 - val_accuracy: 0.2500\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 2.5294 - accuracy: 0.5152 - val_loss: 5.7419 - val_accuracy: 0.2500\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 2.4767 - accuracy: 0.5758 - val_loss: 5.7309 - val_accuracy: 0.2500\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 2.4262 - accuracy: 0.5758 - val_loss: 5.7206 - val_accuracy: 0.2500\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 2.3781 - accuracy: 0.6364 - val_loss: 5.7110 - val_accuracy: 0.2500\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 2.3321 - accuracy: 0.5758 - val_loss: 5.7023 - val_accuracy: 0.2500\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 2.2883 - accuracy: 0.5758 - val_loss: 5.6946 - val_accuracy: 0.2500\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 2.2465 - accuracy: 0.5758 - val_loss: 5.6877 - val_accuracy: 0.2500\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 2.2067 - accuracy: 0.5758 - val_loss: 5.6818 - val_accuracy: 0.3333\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.1689 - accuracy: 0.6061 - val_loss: 5.6767 - val_accuracy: 0.3333\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 2.1330 - accuracy: 0.6061 - val_loss: 5.6725 - val_accuracy: 0.3333\n",
            "Test Set Accuracy 20.0%\n",
            "Mixed Breed Test Set Accuracy 46.666666666666664%\n",
            "Mixed Breed Test Set Top-5 Set Average 2.466666666666667\n",
            "Mixed Breed Test Set Average Distance 1.0012362687541094\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 359ms/step - loss: 8.4051 - accuracy: 0.0606 - val_loss: 7.5253 - val_accuracy: 0.1667\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 8.0593 - accuracy: 0.0606 - val_loss: 7.3614 - val_accuracy: 0.1667\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 7.7277 - accuracy: 0.0606 - val_loss: 7.2139 - val_accuracy: 0.0833\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 7.4117 - accuracy: 0.1515 - val_loss: 7.0814 - val_accuracy: 0.0833\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 7.1123 - accuracy: 0.1818 - val_loss: 6.9624 - val_accuracy: 0.0833\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 6.8296 - accuracy: 0.1818 - val_loss: 6.8556 - val_accuracy: 0.0833\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 6.5636 - accuracy: 0.1818 - val_loss: 6.7601 - val_accuracy: 0.0833\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 6.3136 - accuracy: 0.1818 - val_loss: 6.6752 - val_accuracy: 0.0833\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 6.0786 - accuracy: 0.1818 - val_loss: 6.6007 - val_accuracy: 0.0833\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 5.8575 - accuracy: 0.1818 - val_loss: 6.5366 - val_accuracy: 0.0833\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 5.6486 - accuracy: 0.1818 - val_loss: 6.4831 - val_accuracy: 0.0833\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 5.4503 - accuracy: 0.1818 - val_loss: 6.4411 - val_accuracy: 0.0833\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.2611 - accuracy: 0.1818 - val_loss: 6.4113 - val_accuracy: 0.0833\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 5.0800 - accuracy: 0.1818 - val_loss: 6.3941 - val_accuracy: 0.0833\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 4.9061 - accuracy: 0.1818 - val_loss: 6.3896 - val_accuracy: 0.0833\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 4.7390 - accuracy: 0.1818 - val_loss: 6.3971 - val_accuracy: 0.1667\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 4.5785 - accuracy: 0.2121 - val_loss: 6.4154 - val_accuracy: 0.0833\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 4.4246 - accuracy: 0.2121 - val_loss: 6.4430 - val_accuracy: 0.0833\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 4.2775 - accuracy: 0.2424 - val_loss: 6.4783 - val_accuracy: 0.0833\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 4.1374 - accuracy: 0.2424 - val_loss: 6.5197 - val_accuracy: 0.0833\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 4.0046 - accuracy: 0.2424 - val_loss: 6.5655 - val_accuracy: 0.0833\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 3.8793 - accuracy: 0.2424 - val_loss: 6.6140 - val_accuracy: 0.0833\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 3.7612 - accuracy: 0.2727 - val_loss: 6.6636 - val_accuracy: 0.0833\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 3.6502 - accuracy: 0.3030 - val_loss: 6.7128 - val_accuracy: 0.0833\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 3.5458 - accuracy: 0.3030 - val_loss: 6.7601 - val_accuracy: 0.0833\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 3.4474 - accuracy: 0.3030 - val_loss: 6.8041 - val_accuracy: 0.0833\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 3.3545 - accuracy: 0.3030 - val_loss: 6.8440 - val_accuracy: 0.0833\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 3.2664 - accuracy: 0.3333 - val_loss: 6.8787 - val_accuracy: 0.0833\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 3.1827 - accuracy: 0.3636 - val_loss: 6.9078 - val_accuracy: 0.0833\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 3.1030 - accuracy: 0.3636 - val_loss: 6.9311 - val_accuracy: 0.1667\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 3.0269 - accuracy: 0.3636 - val_loss: 6.9485 - val_accuracy: 0.1667\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 2.9541 - accuracy: 0.4242 - val_loss: 6.9603 - val_accuracy: 0.1667\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 260ms/step - loss: 2.8846 - accuracy: 0.4242 - val_loss: 6.9672 - val_accuracy: 0.1667\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 2.8181 - accuracy: 0.4242 - val_loss: 6.9697 - val_accuracy: 0.1667\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.7545 - accuracy: 0.4848 - val_loss: 6.9688 - val_accuracy: 0.1667\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 256ms/step - loss: 2.6937 - accuracy: 0.5152 - val_loss: 6.9654 - val_accuracy: 0.1667\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 2.6357 - accuracy: 0.5152 - val_loss: 6.9604 - val_accuracy: 0.1667\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 2.5803 - accuracy: 0.5152 - val_loss: 6.9547 - val_accuracy: 0.1667\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 2.5273 - accuracy: 0.6061 - val_loss: 6.9489 - val_accuracy: 0.1667\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 2.4767 - accuracy: 0.6061 - val_loss: 6.9435 - val_accuracy: 0.1667\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 2.4282 - accuracy: 0.6061 - val_loss: 6.9390 - val_accuracy: 0.1667\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 2.3818 - accuracy: 0.6061 - val_loss: 6.9353 - val_accuracy: 0.1667\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 2.3372 - accuracy: 0.6667 - val_loss: 6.9323 - val_accuracy: 0.1667\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 2.2945 - accuracy: 0.6667 - val_loss: 6.9299 - val_accuracy: 0.1667\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 2.2536 - accuracy: 0.6970 - val_loss: 6.9277 - val_accuracy: 0.1667\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 2.2145 - accuracy: 0.6970 - val_loss: 6.9254 - val_accuracy: 0.1667\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 2.1771 - accuracy: 0.6970 - val_loss: 6.9227 - val_accuracy: 0.1667\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 2.1416 - accuracy: 0.6970 - val_loss: 6.9195 - val_accuracy: 0.1667\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 2.1079 - accuracy: 0.6667 - val_loss: 6.9156 - val_accuracy: 0.1667\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 2.0761 - accuracy: 0.6667 - val_loss: 6.9112 - val_accuracy: 0.1667\n",
            "Test Set Accuracy 20.0%\n",
            "Mixed Breed Test Set Accuracy 45.0%\n",
            "Mixed Breed Test Set Top-5 Set Average 2.5\n",
            "Mixed Breed Test Set Average Distance 1.0064323323879492\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 7.8709 - accuracy: 0.1212 - val_loss: 7.5174 - val_accuracy: 0.0833\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 7.5440 - accuracy: 0.1212 - val_loss: 7.2361 - val_accuracy: 0.0833\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 7.2313 - accuracy: 0.1212 - val_loss: 6.9693 - val_accuracy: 0.0833\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 6.9331 - accuracy: 0.1818 - val_loss: 6.7191 - val_accuracy: 0.1667\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 6.6499 - accuracy: 0.1818 - val_loss: 6.4871 - val_accuracy: 0.1667\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 6.3816 - accuracy: 0.2121 - val_loss: 6.2748 - val_accuracy: 0.1667\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 6.1283 - accuracy: 0.2121 - val_loss: 6.0831 - val_accuracy: 0.1667\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 5.8899 - accuracy: 0.1818 - val_loss: 5.9122 - val_accuracy: 0.1667\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 5.6666 - accuracy: 0.1818 - val_loss: 5.7617 - val_accuracy: 0.2500\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 5.4584 - accuracy: 0.1818 - val_loss: 5.6307 - val_accuracy: 0.2500\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 5.2647 - accuracy: 0.1818 - val_loss: 5.5180 - val_accuracy: 0.2500\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 5.0845 - accuracy: 0.2121 - val_loss: 5.4218 - val_accuracy: 0.1667\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 4.9167 - accuracy: 0.2121 - val_loss: 5.3407 - val_accuracy: 0.1667\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 4.7598 - accuracy: 0.2121 - val_loss: 5.2729 - val_accuracy: 0.1667\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 4.6124 - accuracy: 0.2121 - val_loss: 5.2167 - val_accuracy: 0.1667\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 4.4731 - accuracy: 0.2121 - val_loss: 5.1709 - val_accuracy: 0.1667\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 4.3408 - accuracy: 0.2121 - val_loss: 5.1339 - val_accuracy: 0.1667\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 4.2143 - accuracy: 0.2121 - val_loss: 5.1044 - val_accuracy: 0.1667\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 4.0929 - accuracy: 0.2424 - val_loss: 5.0813 - val_accuracy: 0.1667\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 3.9761 - accuracy: 0.2424 - val_loss: 5.0633 - val_accuracy: 0.1667\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 3.8634 - accuracy: 0.3030 - val_loss: 5.0494 - val_accuracy: 0.1667\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 3.7546 - accuracy: 0.3030 - val_loss: 5.0386 - val_accuracy: 0.1667\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 3.6494 - accuracy: 0.3030 - val_loss: 5.0299 - val_accuracy: 0.1667\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.5478 - accuracy: 0.3030 - val_loss: 5.0227 - val_accuracy: 0.1667\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 3.4497 - accuracy: 0.3030 - val_loss: 5.0166 - val_accuracy: 0.1667\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 3.3549 - accuracy: 0.3030 - val_loss: 5.0115 - val_accuracy: 0.1667\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 3.2636 - accuracy: 0.3333 - val_loss: 5.0075 - val_accuracy: 0.1667\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 3.1757 - accuracy: 0.3939 - val_loss: 5.0047 - val_accuracy: 0.1667\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 3.0914 - accuracy: 0.3939 - val_loss: 5.0034 - val_accuracy: 0.1667\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.0107 - accuracy: 0.3939 - val_loss: 5.0036 - val_accuracy: 0.1667\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.9335 - accuracy: 0.4545 - val_loss: 5.0054 - val_accuracy: 0.1667\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.8597 - accuracy: 0.4545 - val_loss: 5.0087 - val_accuracy: 0.1667\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 2.7894 - accuracy: 0.4545 - val_loss: 5.0132 - val_accuracy: 0.1667\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 2.7222 - accuracy: 0.4848 - val_loss: 5.0186 - val_accuracy: 0.1667\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.6581 - accuracy: 0.4848 - val_loss: 5.0246 - val_accuracy: 0.1667\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 2.5968 - accuracy: 0.4848 - val_loss: 5.0307 - val_accuracy: 0.1667\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 2.5382 - accuracy: 0.4848 - val_loss: 5.0366 - val_accuracy: 0.1667\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 2.4821 - accuracy: 0.5455 - val_loss: 5.0421 - val_accuracy: 0.1667\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.4283 - accuracy: 0.5455 - val_loss: 5.0468 - val_accuracy: 0.1667\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.3768 - accuracy: 0.5455 - val_loss: 5.0506 - val_accuracy: 0.1667\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.3275 - accuracy: 0.5758 - val_loss: 5.0534 - val_accuracy: 0.1667\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 2.2803 - accuracy: 0.5758 - val_loss: 5.0551 - val_accuracy: 0.1667\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 2.2350 - accuracy: 0.6061 - val_loss: 5.0558 - val_accuracy: 0.1667\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 2.1918 - accuracy: 0.6667 - val_loss: 5.0557 - val_accuracy: 0.1667\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 2.1504 - accuracy: 0.6667 - val_loss: 5.0549 - val_accuracy: 0.1667\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 2.1110 - accuracy: 0.6667 - val_loss: 5.0536 - val_accuracy: 0.1667\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 2.0734 - accuracy: 0.6970 - val_loss: 5.0521 - val_accuracy: 0.1667\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 2.0377 - accuracy: 0.7273 - val_loss: 5.0506 - val_accuracy: 0.1667\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 2.0038 - accuracy: 0.7273 - val_loss: 5.0494 - val_accuracy: 0.1667\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 1.9719 - accuracy: 0.7273 - val_loss: 5.0486 - val_accuracy: 0.1667\n",
            "Test Set Accuracy 13.333333333333334%\n",
            "Mixed Breed Test Set Accuracy 46.666666666666664%\n",
            "Mixed Breed Test Set Top-5 Set Average 2.4833333333333334\n",
            "Mixed Breed Test Set Average Distance 1.027065143667777\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 493ms/step - loss: 7.6967 - accuracy: 0.1212 - val_loss: 8.3701 - val_accuracy: 0.0833\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 7.3342 - accuracy: 0.1212 - val_loss: 8.2059 - val_accuracy: 0.0833\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 6.9897 - accuracy: 0.1212 - val_loss: 8.0601 - val_accuracy: 0.1667\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 6.6653 - accuracy: 0.2121 - val_loss: 7.9289 - val_accuracy: 0.1667\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 6.3619 - accuracy: 0.2424 - val_loss: 7.8108 - val_accuracy: 0.1667\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 6.0797 - accuracy: 0.2727 - val_loss: 7.7054 - val_accuracy: 0.1667\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 5.8178 - accuracy: 0.2727 - val_loss: 7.6126 - val_accuracy: 0.1667\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 5.5753 - accuracy: 0.2424 - val_loss: 7.5312 - val_accuracy: 0.1667\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 262ms/step - loss: 5.3514 - accuracy: 0.2424 - val_loss: 7.4594 - val_accuracy: 0.0833\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 5.1452 - accuracy: 0.2424 - val_loss: 7.3944 - val_accuracy: 0.0833\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 4.9552 - accuracy: 0.2727 - val_loss: 7.3335 - val_accuracy: 0.0833\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 4.7799 - accuracy: 0.2727 - val_loss: 7.2747 - val_accuracy: 0.0833\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 4.6175 - accuracy: 0.3030 - val_loss: 7.2163 - val_accuracy: 0.0833\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 4.4664 - accuracy: 0.3333 - val_loss: 7.1576 - val_accuracy: 0.0833\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 4.3254 - accuracy: 0.3333 - val_loss: 7.0983 - val_accuracy: 0.0833\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 4.1933 - accuracy: 0.3030 - val_loss: 7.0382 - val_accuracy: 0.0833\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 4.0689 - accuracy: 0.3030 - val_loss: 6.9776 - val_accuracy: 0.0833\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 3.9515 - accuracy: 0.3333 - val_loss: 6.9167 - val_accuracy: 0.0833\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 3.8401 - accuracy: 0.3030 - val_loss: 6.8558 - val_accuracy: 0.0833\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 3.7340 - accuracy: 0.3030 - val_loss: 6.7951 - val_accuracy: 0.0833\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 3.6326 - accuracy: 0.3030 - val_loss: 6.7349 - val_accuracy: 0.0833\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 3.5353 - accuracy: 0.3030 - val_loss: 6.6754 - val_accuracy: 0.0833\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 3.4419 - accuracy: 0.3333 - val_loss: 6.6171 - val_accuracy: 0.0833\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 3.3519 - accuracy: 0.3333 - val_loss: 6.5604 - val_accuracy: 0.1667\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.2654 - accuracy: 0.4242 - val_loss: 6.5055 - val_accuracy: 0.1667\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 3.1820 - accuracy: 0.3939 - val_loss: 6.4531 - val_accuracy: 0.1667\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 3.1017 - accuracy: 0.3939 - val_loss: 6.4035 - val_accuracy: 0.1667\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.0244 - accuracy: 0.4242 - val_loss: 6.3571 - val_accuracy: 0.1667\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.9500 - accuracy: 0.4242 - val_loss: 6.3140 - val_accuracy: 0.1667\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 2.8786 - accuracy: 0.4545 - val_loss: 6.2744 - val_accuracy: 0.1667\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.8099 - accuracy: 0.4848 - val_loss: 6.2384 - val_accuracy: 0.1667\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 2.7441 - accuracy: 0.4848 - val_loss: 6.2058 - val_accuracy: 0.1667\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 2.6811 - accuracy: 0.4848 - val_loss: 6.1767 - val_accuracy: 0.1667\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 2.6209 - accuracy: 0.4848 - val_loss: 6.1509 - val_accuracy: 0.1667\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 2.5636 - accuracy: 0.5455 - val_loss: 6.1282 - val_accuracy: 0.1667\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 2.5092 - accuracy: 0.5152 - val_loss: 6.1084 - val_accuracy: 0.1667\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 2.4576 - accuracy: 0.5152 - val_loss: 6.0914 - val_accuracy: 0.1667\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 2.4087 - accuracy: 0.5455 - val_loss: 6.0769 - val_accuracy: 0.1667\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 2.3624 - accuracy: 0.5455 - val_loss: 6.0645 - val_accuracy: 0.1667\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 2.3186 - accuracy: 0.5758 - val_loss: 6.0540 - val_accuracy: 0.1667\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 2.2771 - accuracy: 0.5758 - val_loss: 6.0448 - val_accuracy: 0.1667\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.2376 - accuracy: 0.5758 - val_loss: 6.0368 - val_accuracy: 0.1667\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.2000 - accuracy: 0.6061 - val_loss: 6.0294 - val_accuracy: 0.1667\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 2.1642 - accuracy: 0.6061 - val_loss: 6.0224 - val_accuracy: 0.1667\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 2.1299 - accuracy: 0.6364 - val_loss: 6.0155 - val_accuracy: 0.1667\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 2.0973 - accuracy: 0.6061 - val_loss: 6.0085 - val_accuracy: 0.1667\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 2.0661 - accuracy: 0.6364 - val_loss: 6.0012 - val_accuracy: 0.1667\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.0364 - accuracy: 0.6364 - val_loss: 5.9935 - val_accuracy: 0.1667\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 2.0083 - accuracy: 0.6667 - val_loss: 5.9853 - val_accuracy: 0.1667\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 1.9816 - accuracy: 0.6667 - val_loss: 5.9766 - val_accuracy: 0.1667\n",
            "Test Set Accuracy 13.333333333333334%\n",
            "Mixed Breed Test Set Accuracy 43.333333333333336%\n",
            "Mixed Breed Test Set Top-5 Set Average 2.6\n",
            "Mixed Breed Test Set Average Distance 1.0104277836478859\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 8.3773 - accuracy: 0.0000e+00 - val_loss: 8.0141 - val_accuracy: 0.1667\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 7.9842 - accuracy: 0.0000e+00 - val_loss: 7.8399 - val_accuracy: 0.1667\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 7.6056 - accuracy: 0.0000e+00 - val_loss: 7.6779 - val_accuracy: 0.0833\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 7.2447 - accuracy: 0.0303 - val_loss: 7.5279 - val_accuracy: 0.0833\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 6.9041 - accuracy: 0.0909 - val_loss: 7.3891 - val_accuracy: 0.0833\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 6.5862 - accuracy: 0.0909 - val_loss: 7.2607 - val_accuracy: 0.0833\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 6.2916 - accuracy: 0.0909 - val_loss: 7.1423 - val_accuracy: 0.0833\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6.0204 - accuracy: 0.0909 - val_loss: 7.0338 - val_accuracy: 0.0833\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 5.7716 - accuracy: 0.1212 - val_loss: 6.9352 - val_accuracy: 0.0833\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 5.5434 - accuracy: 0.1212 - val_loss: 6.8472 - val_accuracy: 0.0833\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.3331 - accuracy: 0.1212 - val_loss: 6.7700 - val_accuracy: 0.1667\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 5.1379 - accuracy: 0.1515 - val_loss: 6.7041 - val_accuracy: 0.1667\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 4.9561 - accuracy: 0.1515 - val_loss: 6.6494 - val_accuracy: 0.1667\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 4.7862 - accuracy: 0.1515 - val_loss: 6.6052 - val_accuracy: 0.1667\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 4.6274 - accuracy: 0.1515 - val_loss: 6.5703 - val_accuracy: 0.1667\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 4.4790 - accuracy: 0.1212 - val_loss: 6.5429 - val_accuracy: 0.1667\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 4.3401 - accuracy: 0.1212 - val_loss: 6.5206 - val_accuracy: 0.1667\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.2096 - accuracy: 0.1212 - val_loss: 6.5011 - val_accuracy: 0.1667\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 4.0865 - accuracy: 0.1515 - val_loss: 6.4822 - val_accuracy: 0.1667\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 3.9699 - accuracy: 0.1818 - val_loss: 6.4623 - val_accuracy: 0.1667\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 3.8588 - accuracy: 0.2121 - val_loss: 6.4403 - val_accuracy: 0.1667\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 3.7525 - accuracy: 0.2424 - val_loss: 6.4156 - val_accuracy: 0.1667\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 3.6503 - accuracy: 0.2727 - val_loss: 6.3878 - val_accuracy: 0.1667\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 3.5518 - accuracy: 0.2727 - val_loss: 6.3571 - val_accuracy: 0.1667\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 3.4567 - accuracy: 0.2727 - val_loss: 6.3238 - val_accuracy: 0.1667\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 3.3647 - accuracy: 0.3030 - val_loss: 6.2883 - val_accuracy: 0.1667\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 3.2759 - accuracy: 0.3333 - val_loss: 6.2511 - val_accuracy: 0.1667\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 3.1903 - accuracy: 0.3636 - val_loss: 6.2129 - val_accuracy: 0.1667\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 3.1082 - accuracy: 0.3636 - val_loss: 6.1744 - val_accuracy: 0.1667\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 3.0297 - accuracy: 0.4242 - val_loss: 6.1362 - val_accuracy: 0.1667\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 2.9549 - accuracy: 0.4545 - val_loss: 6.0988 - val_accuracy: 0.1667\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 2.8840 - accuracy: 0.4545 - val_loss: 6.0629 - val_accuracy: 0.1667\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 2.8171 - accuracy: 0.4848 - val_loss: 6.0289 - val_accuracy: 0.1667\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 2.7539 - accuracy: 0.4848 - val_loss: 5.9974 - val_accuracy: 0.1667\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.6944 - accuracy: 0.4848 - val_loss: 5.9686 - val_accuracy: 0.1667\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 2.6382 - accuracy: 0.4848 - val_loss: 5.9428 - val_accuracy: 0.1667\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 2.5851 - accuracy: 0.5152 - val_loss: 5.9200 - val_accuracy: 0.1667\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 2.5347 - accuracy: 0.5455 - val_loss: 5.9004 - val_accuracy: 0.1667\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.4868 - accuracy: 0.5455 - val_loss: 5.8839 - val_accuracy: 0.1667\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.4413 - accuracy: 0.5758 - val_loss: 5.8702 - val_accuracy: 0.1667\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 2.3979 - accuracy: 0.6667 - val_loss: 5.8592 - val_accuracy: 0.1667\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 2.3565 - accuracy: 0.6667 - val_loss: 5.8505 - val_accuracy: 0.1667\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 2.3172 - accuracy: 0.6667 - val_loss: 5.8439 - val_accuracy: 0.1667\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 2.2798 - accuracy: 0.6667 - val_loss: 5.8390 - val_accuracy: 0.1667\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.2442 - accuracy: 0.6667 - val_loss: 5.8353 - val_accuracy: 0.1667\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.2103 - accuracy: 0.6667 - val_loss: 5.8325 - val_accuracy: 0.1667\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 2.1781 - accuracy: 0.6667 - val_loss: 5.8301 - val_accuracy: 0.1667\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.1474 - accuracy: 0.6667 - val_loss: 5.8277 - val_accuracy: 0.2500\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 2.1182 - accuracy: 0.7576 - val_loss: 5.8250 - val_accuracy: 0.2500\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 2.0903 - accuracy: 0.7576 - val_loss: 5.8218 - val_accuracy: 0.2500\n",
            "Test Set Accuracy 46.666666666666664%\n",
            "Mixed Breed Test Set Accuracy 58.333333333333336%\n",
            "Mixed Breed Test Set Top-5 Set Average 2.433333333333333\n",
            "Mixed Breed Test Set Average Distance 0.9499548643616665\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 8.4835 - accuracy: 0.0909 - val_loss: 6.6461 - val_accuracy: 0.1667\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 8.1399 - accuracy: 0.0909 - val_loss: 6.5180 - val_accuracy: 0.1667\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 7.8107 - accuracy: 0.1212 - val_loss: 6.4037 - val_accuracy: 0.3333\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 7.4982 - accuracy: 0.1515 - val_loss: 6.3035 - val_accuracy: 0.3333\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 7.2036 - accuracy: 0.1515 - val_loss: 6.2170 - val_accuracy: 0.4167\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 6.9275 - accuracy: 0.1515 - val_loss: 6.1427 - val_accuracy: 0.4167\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 6.6698 - accuracy: 0.1515 - val_loss: 6.0788 - val_accuracy: 0.4167\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 6.4298 - accuracy: 0.1515 - val_loss: 6.0226 - val_accuracy: 0.4167\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 6.2060 - accuracy: 0.1818 - val_loss: 5.9716 - val_accuracy: 0.4167\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 5.9962 - accuracy: 0.1515 - val_loss: 5.9238 - val_accuracy: 0.4167\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 5.7984 - accuracy: 0.1818 - val_loss: 5.8779 - val_accuracy: 0.4167\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 5.6107 - accuracy: 0.1818 - val_loss: 5.8334 - val_accuracy: 0.4167\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 5.4316 - accuracy: 0.1818 - val_loss: 5.7906 - val_accuracy: 0.3333\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 5.2602 - accuracy: 0.2121 - val_loss: 5.7496 - val_accuracy: 0.2500\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 5.0959 - accuracy: 0.2121 - val_loss: 5.7109 - val_accuracy: 0.2500\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 4.9384 - accuracy: 0.1818 - val_loss: 5.6749 - val_accuracy: 0.2500\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 4.7873 - accuracy: 0.1818 - val_loss: 5.6419 - val_accuracy: 0.2500\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 4.6423 - accuracy: 0.1818 - val_loss: 5.6120 - val_accuracy: 0.2500\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 4.5034 - accuracy: 0.1818 - val_loss: 5.5849 - val_accuracy: 0.2500\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 4.3703 - accuracy: 0.1818 - val_loss: 5.5603 - val_accuracy: 0.2500\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.2431 - accuracy: 0.1818 - val_loss: 5.5377 - val_accuracy: 0.3333\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 4.1220 - accuracy: 0.2424 - val_loss: 5.5167 - val_accuracy: 0.3333\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 4.0070 - accuracy: 0.2727 - val_loss: 5.4968 - val_accuracy: 0.3333\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 3.8983 - accuracy: 0.2727 - val_loss: 5.4778 - val_accuracy: 0.3333\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 3.7954 - accuracy: 0.3333 - val_loss: 5.4593 - val_accuracy: 0.3333\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 3.6979 - accuracy: 0.3636 - val_loss: 5.4413 - val_accuracy: 0.3333\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 3.6051 - accuracy: 0.3939 - val_loss: 5.4236 - val_accuracy: 0.3333\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 3.5161 - accuracy: 0.3939 - val_loss: 5.4061 - val_accuracy: 0.3333\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 3.4302 - accuracy: 0.3939 - val_loss: 5.3888 - val_accuracy: 0.2500\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 3.3468 - accuracy: 0.3939 - val_loss: 5.3720 - val_accuracy: 0.2500\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 3.2654 - accuracy: 0.4242 - val_loss: 5.3559 - val_accuracy: 0.2500\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 3.1859 - accuracy: 0.4242 - val_loss: 5.3407 - val_accuracy: 0.2500\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 3.1084 - accuracy: 0.4242 - val_loss: 5.3269 - val_accuracy: 0.2500\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 3.0333 - accuracy: 0.4242 - val_loss: 5.3147 - val_accuracy: 0.2500\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.9607 - accuracy: 0.4242 - val_loss: 5.3044 - val_accuracy: 0.2500\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 2.8910 - accuracy: 0.4848 - val_loss: 5.2961 - val_accuracy: 0.2500\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 2.8244 - accuracy: 0.5152 - val_loss: 5.2895 - val_accuracy: 0.3333\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 2.7610 - accuracy: 0.5455 - val_loss: 5.2845 - val_accuracy: 0.3333\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 2.7008 - accuracy: 0.5455 - val_loss: 5.2806 - val_accuracy: 0.3333\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 2.6437 - accuracy: 0.5455 - val_loss: 5.2773 - val_accuracy: 0.3333\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 2.5897 - accuracy: 0.5758 - val_loss: 5.2739 - val_accuracy: 0.3333\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 2.5384 - accuracy: 0.5455 - val_loss: 5.2699 - val_accuracy: 0.3333\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 2.4898 - accuracy: 0.5758 - val_loss: 5.2647 - val_accuracy: 0.3333\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.4434 - accuracy: 0.5758 - val_loss: 5.2579 - val_accuracy: 0.3333\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 2.3991 - accuracy: 0.5758 - val_loss: 5.2493 - val_accuracy: 0.3333\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 2.3568 - accuracy: 0.6061 - val_loss: 5.2387 - val_accuracy: 0.3333\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 2.3164 - accuracy: 0.6061 - val_loss: 5.2262 - val_accuracy: 0.3333\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 2.2779 - accuracy: 0.6364 - val_loss: 5.2119 - val_accuracy: 0.3333\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 2.2413 - accuracy: 0.6667 - val_loss: 5.1961 - val_accuracy: 0.3333\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 2.2066 - accuracy: 0.6364 - val_loss: 5.1792 - val_accuracy: 0.3333\n",
            "Test Set Accuracy 6.666666666666667%\n",
            "Mixed Breed Test Set Accuracy 43.333333333333336%\n",
            "Mixed Breed Test Set Top-5 Set Average 2.5\n",
            "Mixed Breed Test Set Average Distance 1.0051150198386631\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd \n",
        "\n",
        "results = [[0 for j in range(3)] for i in range(10)]\n",
        "\n",
        "print(bottle_neck_set_segmented.shape)\n",
        "print(targets.shape)\n",
        "\n",
        "#loop 10 times to get multiple results in order to calculate p-value\n",
        "for x in range(10):\n",
        "\n",
        "    bottle_neck_train_set_segmented, bottle_neck_test_set_segmented, targets_train, targets_test = train_test_split(bottle_neck_set_segmented, targets, test_size=0.25)#, random_state=87)\n",
        "\n",
        "    bottle_neck_train_set_segmented, bottle_neck_val_set_segmented, targets_train, targets_val = train_test_split(bottle_neck_train_set_segmented, targets_train, test_size=0.25) #, random_state=87) # 0.25 x 0.8 = 0.2\n",
        "\n",
        "    model1.compile(loss='categorical_crossentropy',optimizer='adam'\n",
        "                     ,metrics=['accuracy'])\n",
        "\n",
        "    \n",
        "    # ************************************\n",
        "    # LOADING PUREBRED MODEL \n",
        "    model1.load_weights(\"purebreed.best.hdf5\")\n",
        "    # ************************************\n",
        " \n",
        "\n",
        "    from keras.callbacks import ModelCheckpoint\n",
        "    # Comment this line out when looping to avoid \n",
        "    # loading model checkpoints that train on different train/test split\n",
        "    chkp = ModelCheckpoint(\"purebreed.best.hdf5\",verbose=1,  \n",
        "                     save_best_only=True)\n",
        "    model1.fit(bottle_neck_train_set_segmented,targets_train,\n",
        "              batch_size=64,epochs=50,verbose=1,\n",
        "             validation_data=(bottle_neck_val_set_segmented,targets_val),\n",
        "               shuffle=True)\n",
        "\n",
        "    _pred = []\n",
        "    for i, el in enumerate(bottle_neck_test_set_segmented):\n",
        "        el = el.reshape((1, *el.shape))\n",
        "        _pred.extend(model1(el))\n",
        "    _pred = np.array(_pred) \n",
        "    \n",
        "    _pred_one_class = np.argmax(_pred, axis=1)\n",
        "    original_pred_one_class = np.argmax(np.array(targets_test, dtype=float),axis=1)\n",
        "    \n",
        "    true=[]\n",
        "    \n",
        "    for index in range(len(_pred)):\n",
        "        if(original_pred_one_class[index]==_pred_one_class[index]):\n",
        "            true.append(1) #Appending one if the model got it right otherwise zero\n",
        "        else: \n",
        "            true.append(0)\n",
        "    print(\"Test Set Accuracy {}%\".format((sum(true)/len(true))*100))\n",
        "    \n",
        "    \n",
        "    # Purebred setting\n",
        "    test_targets = alltargets\n",
        "    test_set = bottle_neck_set_complete\n",
        "    \n",
        "    # Mixedbreed setting\n",
        "    #test_targets = targets_test\n",
        "    #test_set = bottle_neck_test_set_segmented\n",
        "    \n",
        "    _pred = []\n",
        "    for i, el in enumerate(test_set):\n",
        "        el = el.reshape((1, *el.shape))\n",
        "        _pred.extend(model1(el))\n",
        "    _pred = np.array(_pred) \n",
        "\n",
        "    original_pred = np.array(test_targets, dtype=float)\n",
        "    _pred_one_class = np.argmax(_pred, axis=1)\n",
        "    original_pred_one_class = np.argmax(np.array(test_targets, dtype=float),axis=1)\n",
        "    _pred_five_class = np.argsort(_pred, axis=1)[:, -5:]\n",
        "    original_pred_five_class = np.argsort(np.array(test_targets, dtype=float),axis=1)[:, -5:]\n",
        "\n",
        "    true=[]\n",
        "    \n",
        "    #metric 1\n",
        "    for index in range(len(_pred)):\n",
        "        if(original_pred_one_class[index]==_pred_one_class[index]):\n",
        "            true.append(1) #Appending one if the model got it right otherwise zero\n",
        "        else: \n",
        "            true.append(0)\n",
        "    print(\"Mixed Breed Test Set Accuracy {}%\".format((sum(true)/len(true))*100))\n",
        "    results[x][0] = sum(true)/len(true)*100\n",
        "\n",
        "    true=[]\n",
        "\n",
        "    #metric 2\n",
        "    for index in range(len(_pred)):\n",
        "        orig_prediction = original_pred_five_class[index]\n",
        "        prediction = _pred_five_class[index]\n",
        "        overlap = 0\n",
        "        for j in range(len(prediction)):\n",
        "            overlap += orig_prediction[j] in prediction\n",
        "        true.append(overlap)\n",
        "\n",
        "    print(\"Mixed Breed Test Set Top-5 Set Average {}\".format((sum(true)/len(true))))\n",
        "    results[x][1] = sum(true)/len(true)\n",
        "\n",
        "    true=[]\n",
        "    #metric 3\n",
        "    for index in range(len(_pred)):\n",
        "        distance = np.sum(np.abs(original_pred[index] - _pred[index]))\n",
        "        true.append(distance)\n",
        "    print(\"Mixed Breed Test Set Average Distance {}\".format((sum(true)/len(true))))\n",
        "    results[x][2] = sum(true)/len(true)\n",
        "    \n",
        "    \n",
        "pd.DataFrame(results).to_csv(\"resultsMixedSingleDataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9ACLib25XGs"
      },
      "outputs": [],
      "source": [
        "#test your own image\n",
        "def Breed(imagePath):\n",
        "  figure = plt.figure(figsize=(20,10))\n",
        "  gs = fig.add_gridspec(2, 3)\n",
        "  image = cv2.imread(imagePath)\n",
        "  ax = figure.add_subplot(gs[0,0])\n",
        "  ax.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))\n",
        "  res = cv2.resize(image,dsize=(299,299),interpolation=cv2.INTER_CUBIC)\n",
        "  res1 = np.zeros([1,299,299,3])\n",
        "  res1[0,:,:,:] = res\n",
        "  print(res.shape)\n",
        "  bottle_neck = model.predict(preprocess_input(res1),verbose=1)\n",
        "  prediction = int(np.argmax(model1.predict(bottle_neck),axis=1))\n",
        "  ax.set_title(\"I think it is \"+dog_names[prediction])\n",
        "  ax1 = figure.add_subplot(gs[1,:])\n",
        "  #print(model1.predict(bottle_neck))\n",
        "  mask = model1.predict(bottle_neck)[0] > 0.03\n",
        "  predicted_dogs = np.array(dog_names)[mask]\n",
        "  predictions = model1.predict(bottle_neck)[0][mask]\n",
        "  ax1.bar(predicted_dogs, predictions)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
